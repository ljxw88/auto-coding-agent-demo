{
  "idea_id": "D3",
  "idea_title": "Cosine LR Schedule with Warmup",
  "git_branch": "experiment/D3-20260219_034410",
  "outcome": "regression",
  "smoke_test": {
    "status": "ok",
    "avg_seconds_per_epoch": 6.67,
    "threshold": 10,
    "smoke_test_epochs": 10,
    "total_elapsed": 66.69
  },
  "metrics": {
    "primary": {
      "name": "accuracy",
      "value": 0.846
    },
    "supporting": {}
  },
  "vs_original_baseline": {
    "baseline_value": 0.84,
    "new_value": 0.846,
    "delta": 0.006,
    "delta_pct": 0.714,
    "improved": true
  },
  "vs_rolling_best": {
    "baseline_value": 0.85,
    "new_value": 0.846,
    "delta": -0.004,
    "delta_pct": -0.471,
    "improved": false
  },
  "branch_kept": false,
  "conclusion": "Cosine LR with warmup scored 84.6% vs rolling best of 85% \u2014 a -0.4pp regression. The hypothesis that proactive cosine annealing improves final accuracy over ReduceLROnPlateau was not confirmed; the dominant factor remains focal loss (E5), not the LR schedule. Validation accuracy was very high (99%+) throughout training, suggesting the model converges well but the val/LocD gap persists regardless of LR schedule.",
  "id": "exp_021"
}